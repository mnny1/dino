Will run the code on one GPU.
| distributed init (rank 0): env://
git:
  sha: 7c446df5b9f45747937fb0d72314eb9f7b66930a, status: has uncommited changes, branch: main
arch: uni
batch_size_per_gpu: 16
clip_grad: 3.0
data_path: /mnt/volume/datasets/NCT-CRC-HE-100K/
dist_url: env://
drop_path_rate: 0.1
epochs: 10
file_extension: .tif
freeze_last_layer: 1
global_crops_scale: (0.4, 1.0)
gpu: 0
json_path: /mnt/volume/sabrina/cellvit_seg/NCT
local_crops_number: 8
local_crops_scale: (0.05, 0.4)
local_rank: 0
lr: 0.0005
min_lr: 1e-06
model_path: /mnt/volume/mathias/pretrained_models/pytorch_model.bin
momentum_teacher: 0.996
norm_last_layer: True
num_workers: 10
optimizer: adamw
out_dim: 65536
output_dir: /mnt/volume/mathias/outputs/test_dino_output/
padding: 1
patch_size: 16
rank: 0
saveckp_freq: 20
seed: 0
teacher_temp: 0.04
use_bn_in_head: False
use_fp16: True
warmup_epochs: 0
warmup_teacher_temp: 0.04
warmup_teacher_temp_epochs: 0
weight_decay: 0.04
weight_decay_end: 0.4
world_size: 1
Using cache found in /home/mathias/.cache/torch/hub/facebookresearch_xcit_main
Data loaded: there are 64 images.
/home/mathias/.conda/envs/masterpraktikum/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.
  warnings.warn("torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.")
All layers frozen except blocks [21, 22, 23]
TokenSelectionWrapper for student & teacher
Student and Teacher are built: they are both uni network.
Loss, optimizer and schedulers ready.
Starting DINO training !
Epoch: [0/10]  [0/4]  eta: 0:00:24  loss: 11.063110 (11.063110)  lr: 0.000031 (0.000031)  wd: 0.040000 (0.040000)  time: 6.090561  data: 2.593479  max mem: 4578
Epoch: [0/10]  [3/4]  eta: 0:00:01  loss: 10.938888 (10.968443)  lr: 0.000031 (0.000031)  wd: 0.040555 (0.041936)  time: 1.740358  data: 0.648430  max mem: 5095
Epoch: [0/10] Total time: 0:00:07 (1.781694 s / it)
Averaged stats: loss: 10.938888 (10.968443)  lr: 0.000031 (0.000031)  wd: 0.040555 (0.041936)
Epoch: [1/10]  [0/4]  eta: 0:00:10  loss: 10.929999 (10.929999)  lr: 0.000031 (0.000031)  wd: 0.048810 (0.048810)  time: 2.564457  data: 2.258024  max mem: 5095
Epoch: [1/10]  [3/4]  eta: 0:00:00  loss: 10.951692 (10.958213)  lr: 0.000030 (0.000030)  wd: 0.053702 (0.057164)  time: 0.859872  data: 0.564552  max mem: 5286
Epoch: [1/10] Total time: 0:00:03 (0.899952 s / it)
Averaged stats: loss: 10.951692 (10.958213)  lr: 0.000030 (0.000030)  wd: 0.053702 (0.057164)
Epoch: [2/10]  [0/4]  eta: 0:00:09  loss: 11.019955 (11.019955)  lr: 0.000028 (0.000028)  wd: 0.074377 (0.074377)  time: 2.429578  data: 2.122195  max mem: 5286
Epoch: [2/10]  [3/4]  eta: 0:00:00  loss: 11.029999 (11.044793)  lr: 0.000027 (0.000027)  wd: 0.083127 (0.088331)  time: 0.826508  data: 0.530607  max mem: 5288
Epoch: [2/10] Total time: 0:00:03 (0.868327 s / it)
Averaged stats: loss: 11.029999 (11.044793)  lr: 0.000027 (0.000027)  wd: 0.083127 (0.088331)
Epoch: [3/10]  [0/4]  eta: 0:00:08  loss: 11.081855 (11.081855)  lr: 0.000025 (0.000025)  wd: 0.114199 (0.114199)  time: 2.232281  data: 1.937420  max mem: 5288
Epoch: [3/10]  [3/4]  eta: 0:00:00  loss: 11.107017 (11.114026)  lr: 0.000023 (0.000023)  wd: 0.125950 (0.132387)  time: 0.777001  data: 0.484423  max mem: 5288
Epoch: [3/10] Total time: 0:00:03 (0.817717 s / it)
Averaged stats: loss: 11.107017 (11.114026)  lr: 0.000023 (0.000023)  wd: 0.125950 (0.132387)
Epoch: [4/10]  [0/4]  eta: 0:00:09  loss: 11.174809 (11.174809)  lr: 0.000021 (0.000021)  wd: 0.164377 (0.164377)  time: 2.350383  data: 2.039409  max mem: 5288
Epoch: [4/10]  [3/4]  eta: 0:00:00  loss: 11.143123 (11.162946)  lr: 0.000018 (0.000019)  wd: 0.177980 (0.185019)  time: 0.806495  data: 0.509913  max mem: 5288
Epoch: [4/10] Total time: 0:00:03 (0.846080 s / it)
Averaged stats: loss: 11.143123 (11.162946)  lr: 0.000018 (0.000019)  wd: 0.177980 (0.185019)
Epoch: [5/10]  [0/4]  eta: 0:00:09  loss: 11.160712 (11.160712)  lr: 0.000016 (0.000016)  wd: 0.220000 (0.220000)  time: 2.445988  data: 2.151972  max mem: 5288
Epoch: [5/10]  [3/4]  eta: 0:00:00  loss: 11.160712 (11.178823)  lr: 0.000014 (0.000014)  wd: 0.234123 (0.241075)  time: 0.830432  data: 0.538055  max mem: 5288
Epoch: [5/10] Total time: 0:00:03 (0.870323 s / it)
Averaged stats: loss: 11.160712 (11.178823)  lr: 0.000014 (0.000014)  wd: 0.234123 (0.241075)
Epoch: [6/10]  [0/4]  eta: 0:00:09  loss: 11.171987 (11.171987)  lr: 0.000011 (0.000011)  wd: 0.275623 (0.275623)  time: 2.365584  data: 2.055319  max mem: 5288
Epoch: [6/10]  [3/4]  eta: 0:00:00  loss: 11.179218 (11.200183)  lr: 0.000009 (0.000010)  wd: 0.288883 (0.295069)  time: 0.811876  data: 0.513886  max mem: 5288
Epoch: [6/10] Total time: 0:00:03 (0.853916 s / it)
Averaged stats: loss: 11.179218 (11.200183)  lr: 0.000009 (0.000010)  wd: 0.288883 (0.295069)
Epoch: [7/10]  [0/4]  eta: 0:00:12  loss: 11.215799 (11.215799)  lr: 0.000007 (0.000007)  wd: 0.325801 (0.325801)  time: 3.237559  data: 2.880472  max mem: 5288
Epoch: [7/10]  [3/4]  eta: 0:00:01  loss: 11.182608 (11.196047)  lr: 0.000005 (0.000006)  wd: 0.336901 (0.341714)  time: 1.035661  data: 0.720188  max mem: 5288
Epoch: [7/10] Total time: 0:00:04 (1.118288 s / it)
Averaged stats: loss: 11.182608 (11.196047)  lr: 0.000005 (0.000006)  wd: 0.336901 (0.341714)
Epoch: [8/10]  [0/4]  eta: 0:00:13  loss: 11.241709 (11.241709)  lr: 0.000004 (0.000004)  wd: 0.365623 (0.365623)  time: 3.475893  data: 3.179660  max mem: 5288
Epoch: [8/10]  [3/4]  eta: 0:00:01  loss: 11.186378 (11.200272)  lr: 0.000003 (0.000003)  wd: 0.373475 (0.376444)  time: 1.093233  data: 0.794985  max mem: 5288
Epoch: [8/10] Total time: 0:00:04 (1.220694 s / it)
Averaged stats: loss: 11.186378 (11.200272)  lr: 0.000003 (0.000003)  wd: 0.373475 (0.376444)
Epoch: [9/10]  [0/4]  eta: 0:00:13  loss: 11.240783 (11.240783)  lr: 0.000002 (0.000002)  wd: 0.391190 (0.391190)  time: 3.314954  data: 3.001734  max mem: 5288
Epoch: [9/10]  [3/4]  eta: 0:00:01  loss: 11.215104 (11.218478)  lr: 0.000001 (0.000001)  wd: 0.395027 (0.395861)  time: 1.051545  data: 0.750492  max mem: 5288
Epoch: [9/10] Total time: 0:00:04 (1.142077 s / it)
Averaged stats: loss: 11.215104 (11.218478)  lr: 0.000001 (0.000001)  wd: 0.395027 (0.395861)